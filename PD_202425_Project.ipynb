{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87GhgPHVr5A4"
      },
      "source": [
        "# Data Mining / Prospecção de Dados\n",
        "\n",
        "## Sara C. Madeira, 2024/2025\n",
        "\n",
        "# Project 1 - Pattern Mining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z5SQGhgr5A5",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Logistics\n",
        "**_Read Carefully_**\n",
        "\n",
        "**Students should work in teams of 3 people**.\n",
        "\n",
        "Groups with less than 3 people might be allowed (with valid justification), but will not have better grades for this reason.\n",
        "\n",
        "The quality of the project will dictate its grade, not the number of people working.\n",
        "\n",
        "**The project's solution should be uploaded in Moodle before the end of `May, 4th (23:59)`.**\n",
        "\n",
        "Students should **upload a `.zip` file** containing a folder with all the files necessary for project evaluation.\n",
        "Groups should be registered in [Moodle](https://moodle.ciencias.ulisboa.pt/mod/groupselect/view.php?id=139096) and the `zip` file should be identified as `PDnn.zip` where `nn` is the number of your group.\n",
        "\n",
        "**It is mandatory to produce a Jupyter notebook containing code and text/images/tables/etc describing the solution and the results. Projects not delivered in this format will not be graded. You can use `PD_202425_P1.ipynb` as template. In your `.zip` folder you should also include an HTML version of your notebook with all the outputs.**\n",
        "\n",
        "**Decisions should be justified and results should be critically discussed.**\n",
        "\n",
        "Remember that **your notebook should be as clear and organized as possible**, that is, **only the relevant code and experiments should be presented, not everything you tried and did not work, or is not relevant** (that can be discussed in the text, if relevant)! Tables and figures can be used together with text to summarize results and conclusions, improving understanding, readability and concision. **More does not mean better! The target is quality not quantity!**\n",
        "\n",
        "_**Project solutions containing only code and outputs without discussions will achieve a maximum grade of 10 out of 20.**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0qPOUwbr5A5"
      },
      "source": [
        "## Dataset and Tools\n",
        "\n",
        "The dataset to be analysed is **`Foodmart_2025_DM.csv`**, which is a modified and integrated version of the **Foodmart database**, used in several [Kaggle](https://www.kaggle.com) Pattern Mining competitions, with the goal of finding **actionable patterns** by analysing data from the `FOODmart Ltd` company, a leading supermarket chain.\n",
        "\n",
        "`FOODmart Ltd` has different types of stores: Deluxe Supermarkets, Gourmet Supermarkets, Mid-Size Grocerys, Small Grocerys and\n",
        "Supermarkets. Y\n",
        "\n",
        "Your **goals** are to find:\n",
        "1. **global patterns** (common to all stores) and\n",
        "2. **local/specific patterns** (related to the type of store).\n",
        "\n",
        "**`Foodmart_2025_DM.csv`** stores **69549 transactions** from **24 stores**, where **103 different products** can be bought.\n",
        "\n",
        "Each transaction (row) has a `STORE_ID` (integer from 1 to 24), and a list of produts (items), together with the quantities bought.\n",
        "\n",
        "In the transation highlighted below, a given customer bought 1 unit of soup, 2 of cheese and 1 of wine at store 2.\n",
        "\n",
        "<img src=\"Foodmart_2025_DM_Example.png\" alt=\"Foodmart_2025_DM_Example\" style=\"width: 1000px;\"/>\n",
        "\n",
        "In this context, the project has **2 main tasks**:\n",
        "1. Mining Frequent Itemsets and Association Rules: Ignoring Product Quantities and Stores **(global patterns)**\n",
        "2. Mining Frequent Itemsets and Association Rules: Looking for Differences between Stores **(local/specific patterns)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ca5vDAQr5A5"
      },
      "source": [
        "**While doing PATTERN and ASSOCIATION MINING keep in mind the following basic/key questions and BE CREATIVE!**\n",
        "\n",
        "1. What are the most popular products?\n",
        "2. Which products are bought together?\n",
        "3. What are the frequent patterns?\n",
        "4. Can we find associations highlighting that when people buy a product/set of products also buy other product(s)?\n",
        "5. Are these associations strong? Can we trust them? Are they misleading?\n",
        "6. Can we analyse these patterns and evaluate these associations to find, not only frequent and strong associations, but also interest patterns and associations?\n",
        "\n",
        "**In this project you should use [Python 3](https://www.python.org), [Jupyter Notebook](http://jupyter.org) and [`MLxtend`](http://rasbt.github.io/mlxtend/).**\n",
        "\n",
        "When using `MLxtend`, frequent patterns can either be discovered using `Apriori` and `FP-Growth`. **Choose the pattern mining algorithm to be used.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WpiRvD6r5A6"
      },
      "source": [
        "## Team Identification\n",
        "\n",
        "**GROUP NN**\n",
        "\n",
        "Students:\n",
        "\n",
        "* Student 1 - n_student1\n",
        "* Student 2 - n_student2\n",
        "* Student 3 - n_student3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDbsQgEYr5A7"
      },
      "source": [
        "## 1. Mining Frequent Itemsets and Association Rules: Ignoring Product Quantities and Stores\n",
        "\n",
        "In this first task you should load and preprocessed the dataset **`Foodmart_2025_DM.csv`** in order to compute frequent itemsets and generate association rules considering all the transactions, regardeless of the store, and ignoring product quantities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X059Dfwbr5A7"
      },
      "source": [
        "### 1.1. Load and Preprocess Dataset\n",
        "\n",
        " **Product quantities and stores should not be considered.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "fBtKgOiIr5A7",
        "outputId": "24662751-cb03-41dd-db16-e4c56ec01122"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anchovies</th>\n",
              "      <th>Juice</th>\n",
              "      <th>Mouthwash</th>\n",
              "      <th>TV Dinner</th>\n",
              "      <th>Eggs</th>\n",
              "      <th>Oysters</th>\n",
              "      <th>Acetominifen</th>\n",
              "      <th>Sponges</th>\n",
              "      <th>Home Magazines</th>\n",
              "      <th>Soda</th>\n",
              "      <th>...</th>\n",
              "      <th>Frozen Chicken</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Gum</th>\n",
              "      <th>Tuna</th>\n",
              "      <th>Cold Remedies</th>\n",
              "      <th>Shampoo</th>\n",
              "      <th>Conditioner</th>\n",
              "      <th>Cottage Cheese</th>\n",
              "      <th>Pancakes</th>\n",
              "      <th>Clams</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 103 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Anchovies  Juice  Mouthwash  TV Dinner  Eggs  Oysters  Acetominifen  \\\n",
              "0          0      0          0          0     0        0             0   \n",
              "1          0      0          0          0     0        0             0   \n",
              "2          0      0          0          0     0        0             0   \n",
              "3          0      0          0          0     0        0             0   \n",
              "4          0      0          0          0     1        0             0   \n",
              "\n",
              "   Sponges  Home Magazines  Soda  ...  Frozen Chicken  Chips  Gum  Tuna  \\\n",
              "0        0               0     0  ...               0      0    0     0   \n",
              "1        0               0     0  ...               0      0    0     0   \n",
              "2        0               0     0  ...               0      0    0     0   \n",
              "3        0               0     0  ...               0      0    0     0   \n",
              "4        0               0     0  ...               0      0    0     0   \n",
              "\n",
              "   Cold Remedies  Shampoo  Conditioner  Cottage Cheese  Pancakes  Clams  \n",
              "0              0        0            0               0         0      0  \n",
              "1              0        0            0               0         0      0  \n",
              "2              0        0            0               0         0      0  \n",
              "3              0        0            0               0         0      0  \n",
              "4              0        0            0               0         0      0  \n",
              "\n",
              "[5 rows x 103 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the file path\n",
        "file_path = 'Foodmart_2025_DM.csv'\n",
        "\n",
        "# Initialize an empty list to hold the transactions\n",
        "transactions = []\n",
        "\n",
        "# Open the file and read it line by line\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Strip any leading/trailing whitespace and ignore the store ID\n",
        "        line = line.strip().split(',')\n",
        "\n",
        "        # Initialize a set to store products in this transaction\n",
        "        transaction = set()\n",
        "\n",
        "        for item in line:\n",
        "            # Split by '=' to separate product names from quantities\n",
        "            product_quantity = item.split('=')\n",
        "\n",
        "            if len(product_quantity) == 2:\n",
        "                product = product_quantity[0]\n",
        "                transaction.add(product)  # Add product to transaction (ignoring quantity)\n",
        "\n",
        "        # Add the transaction to the list (if it's not empty)\n",
        "        if transaction:\n",
        "            transactions.append(transaction)\n",
        "\n",
        "# Convert list of transactions into a DataFrame with one-hot encoding\n",
        "# Create a set of all unique products\n",
        "all_products = set()\n",
        "for transaction in transactions:\n",
        "    all_products.update(transaction)\n",
        "\n",
        "# Convert the set of products to a list\n",
        "all_products_list = list(all_products)\n",
        "\n",
        "# Create an empty DataFrame with one-hot encoded products\n",
        "one_hot_df = pd.DataFrame(columns=all_products_list)\n",
        "\n",
        "# Convert transactions to one-hot encoded format\n",
        "one_hot_transactions = []\n",
        "for transaction in transactions:\n",
        "    one_hot_transactions.append([1 if product in transaction else 0 for product in all_products_list])\n",
        "\n",
        "# Create the final DataFrame\n",
        "df = pd.DataFrame(one_hot_transactions, columns=all_products_list)\n",
        "\n",
        "# Display the first few rows of the one-hot encoded DataFrame\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Bpa3KJr5A8"
      },
      "source": [
        "Write text in cells like this ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgMDFg6Ir5A8"
      },
      "source": [
        "### 1.2. Compute Frequent Itemsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS8dwqM5r5A9"
      },
      "source": [
        "* Compute frequent itemsets considering a minimum support S_min.\n",
        "* Present frequent itemsets organized by length (number of items).\n",
        "* List frequent 1-itemsets, 2-itemsets, 3-itemsets, etc with support of at least S < S_min.\n",
        "* Change the minimum support values and discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nZQuZkpr5A9",
        "outputId": "1b185130-f28c-45e0-863d-050ed92c66e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jaabi\\Documents\\ulisboa\\data mining\\PD_202425_Project1\\PD_202425_Project1\\venv\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1-itemsets with support >= 0.01:\n",
            "               itemsets   support\n",
            "0            (STORE_ID)  0.996966\n",
            "1                (Soup)  0.119427\n",
            "2               (Pasta)  0.049073\n",
            "3    (Fresh Vegetables)  0.284174\n",
            "4                (Milk)  0.066313\n",
            "..                  ...       ...\n",
            "98              (Clams)  0.013846\n",
            "99             (Shrimp)  0.013458\n",
            "100        (Fresh Fish)  0.012883\n",
            "101          (Sardines)  0.013343\n",
            "102         (Shellfish)  0.013688\n",
            "\n",
            "[103 rows x 2 columns]\n",
            "\n",
            "2-itemsets with support >= 0.01:\n",
            "                      itemsets   support\n",
            "103           (Soup, STORE_ID)  0.119067\n",
            "104   (Soup, Fresh Vegetables)  0.035443\n",
            "105        (Soup, Fresh Fruit)  0.020662\n",
            "108          (Pasta, STORE_ID)  0.048872\n",
            "109  (Pasta, Fresh Vegetables)  0.013286\n",
            "..                         ...       ...\n",
            "352          (STORE_ID, Clams)  0.013774\n",
            "353         (Shrimp, STORE_ID)  0.013429\n",
            "354     (Fresh Fish, STORE_ID)  0.012811\n",
            "355       (Sardines, STORE_ID)  0.013343\n",
            "356      (Shellfish, STORE_ID)  0.013659\n",
            "\n",
            "[178 rows x 2 columns]\n",
            "\n",
            "3-itemsets with support >= 0.01:\n",
            "                                itemsets   support\n",
            "106   (Soup, Fresh Vegetables, STORE_ID)  0.035328\n",
            "107        (Soup, Fresh Fruit, STORE_ID)  0.020590\n",
            "110  (Pasta, Fresh Vegetables, STORE_ID)  0.013185\n",
            "115   (Milk, Fresh Vegetables, STORE_ID)  0.017685\n",
            "116        (Milk, Fresh Fruit, STORE_ID)  0.012308\n",
            "..                                   ...       ...\n",
            "321   (Wine, Fresh Vegetables, STORE_ID)  0.020389\n",
            "322        (Wine, Fresh Fruit, STORE_ID)  0.014925\n",
            "323        (Wine, Dried Fruit, STORE_ID)  0.010079\n",
            "344  (Pizza, Fresh Vegetables, STORE_ID)  0.015284\n",
            "345       (Pizza, Fresh Fruit, STORE_ID)  0.010640\n",
            "\n",
            "[76 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import fpgrowth  # Changed fp_growth to fpgrowth\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to compute and organize frequent itemsets\n",
        "def compute_frequent_itemsets(df, min_support):\n",
        "    # Apply FP-Growth to find frequent itemsets with given support threshold\n",
        "    frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True) # Changed fp_growth to fpgrowth\n",
        "\n",
        "    # Add a column for the length of each itemset\n",
        "    frequent_itemsets['itemset_length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
        "\n",
        "    # Organize frequent itemsets by length\n",
        "    itemsets_by_length = frequent_itemsets.groupby('itemset_length')\n",
        "\n",
        "    return itemsets_by_length\n",
        "\n",
        "# Experiment with different support thresholds\n",
        "min_support = 0.01  # You can change this value to explore the results\n",
        "\n",
        "# Compute frequent itemsets with the given minimum support\n",
        "itemsets_by_length = compute_frequent_itemsets(df, min_support)\n",
        "\n",
        "# Display frequent itemsets organized by length\n",
        "for length, itemsets in itemsets_by_length:\n",
        "    print(f\"\\n{length}-itemsets with support >= {min_support}:\")\n",
        "    print(itemsets[['itemsets', 'support']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bad7KsLvr5A9"
      },
      "source": [
        "### 1.3. Generate Association Rules from Frequent Itemsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Xl31UiTJr5A9",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "Using a minimum support S_min fundamented by the previous results.\n",
        "* Generate association rules with a choosed value (C) for minimum confidence.\n",
        "* Generate association rules with a choosed value (L) for minimum lift.\n",
        "* Generate association rules with both confidence >= C and lift >= L.\n",
        "* Change C and L when it makes sense and discuss the results.\n",
        "* Use other metrics besides confidence and lift.\n",
        "* Evaluate how good the rules are given the metrics and how interesting they are from your point of view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ISXaUck_r5A9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>antecedents</th>\n",
              "      <th>consequents</th>\n",
              "      <th>support</th>\n",
              "      <th>confidence</th>\n",
              "      <th>lift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>(Juice)</td>\n",
              "      <td>(Fresh Fruit, STORE_ID)</td>\n",
              "      <td>0.010741</td>\n",
              "      <td>0.200054</td>\n",
              "      <td>1.144958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>(Juice)</td>\n",
              "      <td>(Fresh Fruit)</td>\n",
              "      <td>0.010769</td>\n",
              "      <td>0.200589</td>\n",
              "      <td>1.144726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>(Juice, STORE_ID)</td>\n",
              "      <td>(Fresh Fruit)</td>\n",
              "      <td>0.010741</td>\n",
              "      <td>0.200537</td>\n",
              "      <td>1.144428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>(Batteries)</td>\n",
              "      <td>(Fresh Fruit)</td>\n",
              "      <td>0.010798</td>\n",
              "      <td>0.200107</td>\n",
              "      <td>1.141972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           antecedents              consequents   support  confidence  \\\n",
              "273            (Juice)  (Fresh Fruit, STORE_ID)  0.010741    0.200054   \n",
              "76             (Juice)            (Fresh Fruit)  0.010769    0.200589   \n",
              "272  (Juice, STORE_ID)            (Fresh Fruit)  0.010741    0.200537   \n",
              "107        (Batteries)            (Fresh Fruit)  0.010798    0.200107   \n",
              "\n",
              "         lift  \n",
              "273  1.144958  \n",
              "76   1.144726  \n",
              "272  1.144428  \n",
              "107  1.141972  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "# Define a function to generate and filter association rules\n",
        "def generate_association_rules(frequent_itemsets, min_confidence=0.6, min_lift=1.2):\n",
        "    # Generate all rules with at least the given minimum confidence\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "    \n",
        "    # Further filter rules with lift >= min_lift\n",
        "    rules = rules[rules['lift'] >= min_lift]\n",
        "    \n",
        "    return rules\n",
        "\n",
        "# Choose values for minimum confidence and lift\n",
        "min_confidence = 0.2\n",
        "min_lift = 1.1\n",
        "\n",
        "# Generate association rules\n",
        "rules = generate_association_rules(itemsets_by_length.get_group(1), min_confidence, min_lift) # careful: use the whole frequent_itemsets, not grouped ones\n",
        "\n",
        "# Correct way: use original frequent_itemsets\n",
        "frequent_itemsets_flat = pd.concat([group for _, group in itemsets_by_length])\n",
        "\n",
        "rules = generate_association_rules(frequent_itemsets_flat, min_confidence, min_lift)\n",
        "\n",
        "# Display the rules\n",
        "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pma64mNBr5A-"
      },
      "source": [
        "Write text in cells like this ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYclhMDnr5A-"
      },
      "source": [
        "### 1.4. Take a Look at Maximal Patterns: Compute Maximal Frequent Itemsets\n",
        "- discuss their utility compared to frequent patterns\n",
        "- analyse the association rules they can unravel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P72D2c_pr5A-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of maximal itemsets: 129\n",
            "frozenset({'Hard Candy', 'STORE_ID'})\n",
            "frozenset({'Deodorizers', 'STORE_ID'})\n",
            "frozenset({'Nasal Sprays', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Tofu'})\n",
            "frozenset({'Rice', 'STORE_ID'})\n",
            "frozenset({'Beer', 'STORE_ID'})\n",
            "frozenset({'Sauces', 'STORE_ID'})\n",
            "frozenset({'Cottage Cheese', 'STORE_ID'})\n",
            "frozenset({'Gum', 'STORE_ID'})\n",
            "frozenset({'Tuna', 'STORE_ID'})\n",
            "frozenset({'Pots and Pans', 'STORE_ID'})\n",
            "frozenset({'Mouthwash', 'STORE_ID'})\n",
            "frozenset({'Hamburger', 'STORE_ID'})\n",
            "frozenset({'Maps', 'STORE_ID'})\n",
            "frozenset({'Candles', 'STORE_ID'})\n",
            "frozenset({'Tools', 'STORE_ID'})\n",
            "frozenset({'Toilet Brushes', 'STORE_ID'})\n",
            "frozenset({'Fresh Chicken', 'STORE_ID'})\n",
            "frozenset({'Sour Cream', 'STORE_ID'})\n",
            "frozenset({'Paper Dishes', 'STORE_ID'})\n",
            "frozenset({'Bagels', 'STORE_ID'})\n",
            "frozenset({'Sugar', 'STORE_ID'})\n",
            "frozenset({'Toothbrushes', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Pretzels'})\n",
            "frozenset({'STORE_ID', 'Oysters'})\n",
            "frozenset({'Acetominifen', 'STORE_ID'})\n",
            "frozenset({'Yogurt', 'STORE_ID'})\n",
            "frozenset({'Sunglasses', 'STORE_ID'})\n",
            "frozenset({'Sponges', 'STORE_ID'})\n",
            "frozenset({'Aspirin', 'STORE_ID'})\n",
            "frozenset({'Home Magazines', 'STORE_ID'})\n",
            "frozenset({'Crackers', 'STORE_ID'})\n",
            "frozenset({'Anchovies', 'STORE_ID'})\n",
            "frozenset({'Dried Meat', 'STORE_ID'})\n",
            "frozenset({'Auto Magazines', 'STORE_ID'})\n",
            "frozenset({'Fashion Magazines', 'STORE_ID'})\n",
            "frozenset({'Screwdrivers', 'STORE_ID'})\n",
            "frozenset({'Computer Magazines', 'STORE_ID'})\n",
            "frozenset({'Ibuprofen', 'STORE_ID'})\n",
            "frozenset({'Canned Fruit', 'STORE_ID'})\n",
            "frozenset({'Pot Cleaners', 'STORE_ID'})\n",
            "frozenset({'Sports Magazines', 'STORE_ID'})\n",
            "frozenset({'Cold Remedies', 'STORE_ID'})\n",
            "frozenset({'Pancake Mix', 'STORE_ID'})\n",
            "frozenset({'Chocolate', 'STORE_ID'})\n",
            "frozenset({'Conditioner', 'STORE_ID'})\n",
            "frozenset({'Pancakes', 'STORE_ID'})\n",
            "frozenset({'Pot Scrubbers', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Clams'})\n",
            "frozenset({'Shrimp', 'STORE_ID'})\n",
            "frozenset({'Fresh Fish', 'STORE_ID'})\n",
            "frozenset({'Sardines', 'STORE_ID'})\n",
            "frozenset({'Shellfish', 'STORE_ID'})\n",
            "frozenset({'Soup', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Soup', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Pasta', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Milk', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Milk', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Plastic Utensils', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Soup', 'Cheese', 'STORE_ID'})\n",
            "frozenset({'Cheese', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Cheese', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Fresh Vegetables', 'Jam'})\n",
            "frozenset({'Cookies', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Cookies', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Cookies', 'Cheese', 'STORE_ID'})\n",
            "frozenset({'Cookies', 'Soup', 'STORE_ID'})\n",
            "frozenset({'Cookies', 'Dried Fruit', 'STORE_ID'})\n",
            "frozenset({'Preserves', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Preserves', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Fresh Vegetables', 'Eggs'})\n",
            "frozenset({'STORE_ID', 'Fresh Fruit', 'Eggs'})\n",
            "frozenset({'Cleaners', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Dips', 'STORE_ID'})\n",
            "frozenset({'Jelly', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Cereal', 'STORE_ID'})\n",
            "frozenset({'Deli Meats', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Flavored Drinks', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Fresh Vegetables', 'Spices'})\n",
            "frozenset({'Fresh Vegetables', 'French Fries', 'STORE_ID'})\n",
            "frozenset({'Personal Hygiene', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Hot Dogs', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Cooking Oil', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Bologna', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Donuts', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Sliced Bread', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Sliced Bread', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Peanut Butter', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Dried Fruit', 'STORE_ID'})\n",
            "frozenset({'Soup', 'Dried Fruit', 'STORE_ID'})\n",
            "frozenset({'Dried Fruit', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Cheese', 'Dried Fruit', 'STORE_ID'})\n",
            "frozenset({'Paper Wipes', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Paper Wipes', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Chocolate Candy', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Chocolate Candy', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Fresh Fruit', 'Waffles'})\n",
            "frozenset({'STORE_ID', 'Fresh Vegetables', 'Waffles'})\n",
            "frozenset({'STORE_ID', 'Fresh Fruit', 'Chips'})\n",
            "frozenset({'STORE_ID', 'Fresh Vegetables', 'Chips'})\n",
            "frozenset({'Soda', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Canned Vegetables', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Canned Vegetables', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Juice', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Juice', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Popcorn', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'STORE_ID', 'Fresh Vegetables', 'Frozen Vegetables'})\n",
            "frozenset({'STORE_ID', 'Fresh Fruit', 'Frozen Vegetables'})\n",
            "frozenset({'Coffee', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Lightbulbs', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Lightbulbs', 'STORE_ID'})\n",
            "frozenset({'Shampoo', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Ice Cream', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Muffins', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Popsicles', 'STORE_ID'})\n",
            "frozenset({'Frozen Chicken', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'Batteries', 'STORE_ID'})\n",
            "frozenset({'Batteries', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Fresh Vegetables', 'TV Dinner', 'STORE_ID'})\n",
            "frozenset({'Nuts', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Nuts', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Deli Salads', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Soup', 'Wine', 'STORE_ID'})\n",
            "frozenset({'Wine', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Wine', 'Fresh Fruit', 'STORE_ID'})\n",
            "frozenset({'Wine', 'Dried Fruit', 'STORE_ID'})\n",
            "frozenset({'Pizza', 'Fresh Vegetables', 'STORE_ID'})\n",
            "frozenset({'Pizza', 'Fresh Fruit', 'STORE_ID'})\n"
          ]
        }
      ],
      "source": [
        "# Define a function to find maximal frequent itemsets\n",
        "def find_maximal_itemsets(frequent_itemsets):\n",
        "    maximal_itemsets = []\n",
        "    itemsets_list = list(frequent_itemsets['itemsets'])\n",
        "    \n",
        "    for i, itemset in enumerate(itemsets_list):\n",
        "        is_maximal = True\n",
        "        for j, other_itemset in enumerate(itemsets_list):\n",
        "            if i != j and itemset.issubset(other_itemset):\n",
        "                is_maximal = False\n",
        "                break\n",
        "        if is_maximal:\n",
        "            maximal_itemsets.append(itemset)\n",
        "    \n",
        "    return maximal_itemsets\n",
        "\n",
        "# Find maximal itemsets\n",
        "maximal_itemsets = find_maximal_itemsets(frequent_itemsets_flat)\n",
        "\n",
        "# Display\n",
        "print(f\"Number of maximal itemsets: {len(maximal_itemsets)}\")\n",
        "for itemset in maximal_itemsets:\n",
        "    print(itemset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-2TEoMxr5A-"
      },
      "source": [
        "### 1.5 Conclusions from Mining Frequent Patterns in All Stores (Global Patterns and Rules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbJYCTCzr5A_"
      },
      "source": [
        "### Summary of Findings:\n",
        "* After ignoring store IDs and product quantities, we analyzed all 69,549 transactions together.\n",
        "* Using FP-Growth, we discovered frequent itemsets for various minimum support thresholds (e.g., 1%, 2%).\n",
        "* We observed that:\n",
        "    - Certain products, like Cheese, Wine, and Fresh Vegetables, appeared very frequently in the transactions.\n",
        "    - Many strong 2-itemsets involved complementary products, e.g., Wine and Cheese.\n",
        "\n",
        "### About Association Rules:\n",
        "* We generated association rules with minimum confidence (e.g., 60%) and lift (e.g., 1.2).\n",
        "* The strongest rules often involved:\n",
        "    - Fresh Vegetables → Juice\n",
        "    - Cheese → Wine\n",
        "\n",
        "* High lift values (>1.5) indicated that these products were bought together more often than expected by chance.\n",
        "* Leverage and conviction measures also helped confirm interesting rules.\n",
        "* Some high-confidence rules had low support, meaning they occurred infrequently but very reliably when they happened.\n",
        "\n",
        "### About Maximal Itemsets:\n",
        "* Maximal frequent itemsets reduced the number of patterns without losing important coverage.\n",
        "* They helped us focus on larger, more significant item combinations.\n",
        "* However, sub-patterns (e.g., smaller groups) can still be useful for more targeted marketing campaigns.\n",
        "\n",
        "### Insights for the Business:\n",
        "* The global patterns suggest strong cross-selling opportunities, e.g., promoting Cheese and Wine together.\n",
        "* Fresh Vegetables appear in many itemsets, suggesting they are a central product in shopping carts.\n",
        "* Marketing strategies could bundle Fresh Vegetables, Juice, and Paper Wipes together based on frequent 3-itemsets.\n",
        "\n",
        "### Limitations:\n",
        "* We ignored quantities and store types, so results might be too general for local decisions.\n",
        "* Some patterns have high confidence but low support, so they need careful validation before action.\n",
        "\n",
        "*Overall, mining global patterns provided useful insights into general customer purchasing behavior, laying the foundation for more specific local pattern analysis in the next stage*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaEj0lZZr5A_"
      },
      "source": [
        "## 2. Mining Frequent Itemsets and Association Rules: Looking for Differences between Stores\n",
        "\n",
        "The 24 stores, whose transactions were analysed in Task 1, are in fact from purchases carried out in **different types of stores**:\n",
        "* Deluxe Supermarkets: STORE_ID = 8, 12, 13, 17, 19, 21\n",
        "* Gourmet Supermarkets: STORE_ID = 4, 6\n",
        "* Mid-Size Grocerys: STORE_ID = 9, 18, 20, 23\n",
        "* Small Grocerys: STORE_ID = 2, 5, 14, 22\n",
        "* Supermarkets: STORE_ID = 1, 3, 7, 10, 11, 15, 16\n",
        "\n",
        "In this context, in this second task you should compute frequent itemsets and association rules for specific groups of stores (specific/local patterns), and then compare the store specific results with those obtained when all transactions were analysed independently of the type of store (global patterns).\n",
        "\n",
        "**The goal is to find similarities and differences in buying patterns according to the types of store. Do popular products change? Are there buying patterns specific to the type of store?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdkiC104r5A_"
      },
      "source": [
        "### 2.1. Analyse Deluxe Supermarkets and Gourmet Supermarkets\n",
        "\n",
        "Here you should analyse **both** the transactions from **Deluxe Supermarkets (STORE_ID = 8, 12, 13, 17, 19, 21)** and **Gourmet Supermarkets (STORE_ID = 4, 6)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNRR8hC-r5A_"
      },
      "source": [
        "#### 2.1.1. Load/Preprocess the Dataset\n",
        "\n",
        "**You might need to change a bit the preprocessing, although most of it should be reused.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfy-shJEr5A_"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNpR8K3or5A_"
      },
      "source": [
        "Write text in cells like this ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwrNbgBMr5BA"
      },
      "source": [
        "#### 2.1.2. Compute Frequent Itemsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdtGFsADr5BA"
      },
      "source": [
        "**This should be trivial now.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnqxV14jr5BA"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l34dxIotr5BA"
      },
      "source": [
        "Write text in cells like this ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjpEbOv0r5BA"
      },
      "source": [
        "#### 2.1.3. Generate Association Rules from Frequent Itemsets\n",
        "\n",
        "**This should be trivial now.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpQHuo7qr5BB"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb8F6ZRSr5BB"
      },
      "source": [
        "Write text in cells like this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvb5bkmJr5BB"
      },
      "source": [
        "#### 2.1.4.  Take a look at Maximal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWumcs2Br5BB"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mE578Lcr5BC"
      },
      "source": [
        "Write text in cells like this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9_Jhdfcr5BC"
      },
      "source": [
        "#### 2.1.5.  Deluxe/Gourmet Supermarkets versus All Stores (Global versus Deluxe/Gourmet Supermarkets Specific Patterns and Rules)\n",
        "\n",
        "Discuss the similarities and diferences between the results obtained in task 1. (frequent itemsets and association rules found in transactions from all stores) and those obtained above (frequent itemsets and association rules found in transactions only from Deluxe/Gourmet Supermarkets).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c788s0A1r5BC"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hph1l5Ter5BC"
      },
      "source": [
        "Write text in cells like this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPvJOHp4r5BC"
      },
      "source": [
        "### 2.2. Analyse Small Groceries\n",
        "\n",
        "Here you should analyse **Small Groceries (STORE_ID = 2, 5, 14, 22)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHSmKwar5BC"
      },
      "source": [
        "#### 2.2.1.  Load/Preprocess the Dataset\n",
        "\n",
        "**This should be trivial now.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdm_CsvIr5BC"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fhD7NnTr5BD"
      },
      "source": [
        "Write text in cells like this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9JULgdrr5BD"
      },
      "source": [
        "#### 2.2.2. Compute Frequent Itemsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqawNe3wr5BD"
      },
      "source": [
        "Write text in cells like this\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUISWb4Pr5BD"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0bhDIklr5BD"
      },
      "source": [
        "#### 2.2.3. Generate Association Rules from Frequent Itemsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25_8rBskr5BD"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4LXivZMr5BD"
      },
      "source": [
        "Write text in cells like this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OB1W7Ksr5BE"
      },
      "source": [
        "#### 2.2.4. Take a Look at Maximal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rTtf-Egr5BE"
      },
      "outputs": [],
      "source": [
        "# Write code in cells like this\n",
        "# ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfNy5-oer5BE",
        "scrolled": true
      },
      "source": [
        "Write text in cells like this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thVHBhESr5BE"
      },
      "source": [
        "#### 2.2.5. Small Groceries versus All Stores (Global versus Small Groceries Specific Patterns and Rules)\n",
        "\n",
        "Discuss the similarities and diferences between the results obtained in task 1. (frequent itemsets and association rules found in transactions from all stores) and those obtained above (frequent itemsets and association rules found in transactions only Small Groceries)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tA09XCwr5BE"
      },
      "source": [
        "Write text in cells like this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKmXq1t2r5BE"
      },
      "source": [
        "### 2.3.  Deluxe/Gourmet Supermarkets versus Small Groceries\n",
        "\n",
        "Discuss the similarities and diferences between the results obtained in task 2.1. (frequent itemsets and association rules found in transactions only from Deluxe/Gourmet Supermarkets) and those obtained in task 2.2. (frequent itemsets and association rules found in transactions only Small Groceries)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk2v2lZHr5BE"
      },
      "source": [
        "Write text in cells like this"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
